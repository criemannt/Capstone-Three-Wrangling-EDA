{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c44294c",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40ec37b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#datalink because github doesn't l https://www.kaggle.com/competitions/store-sales-time-series-forecasting/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41ae7cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05699fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataFrame:\n",
      "   id       date  store_nbr      family  sales  onpromotion\n",
      "0   0 2013-01-01          1  AUTOMOTIVE    0.0            0\n",
      "1   1 2013-01-01          1   BABY CARE    0.0            0\n",
      "2   2 2013-01-01          1      BEAUTY    0.0            0\n",
      "3   3 2013-01-01          1   BEVERAGES    0.0            0\n",
      "4   4 2013-01-01          1       BOOKS    0.0            0 \n",
      "\n",
      "Test DataFrame:\n",
      "        id       date  store_nbr      family  onpromotion\n",
      "0  3000888 2017-08-16          1  AUTOMOTIVE            0\n",
      "1  3000889 2017-08-16          1   BABY CARE            0\n",
      "2  3000890 2017-08-16          1      BEAUTY            2\n",
      "3  3000891 2017-08-16          1   BEVERAGES           20\n",
      "4  3000892 2017-08-16          1       BOOKS            0 \n",
      "\n",
      "Stores DataFrame:\n",
      "   store_nbr           city                           state type  cluster\n",
      "0          1          Quito                       Pichincha    D       13\n",
      "1          2          Quito                       Pichincha    D       13\n",
      "2          3          Quito                       Pichincha    D        8\n",
      "3          4          Quito                       Pichincha    D        9\n",
      "4          5  Santo Domingo  Santo Domingo de los Tsachilas    D        4 \n",
      "\n",
      "Oil DataFrame:\n",
      "        date  dcoilwtico\n",
      "0 2013-01-01         NaN\n",
      "1 2013-01-02       93.14\n",
      "2 2013-01-03       92.97\n",
      "3 2013-01-04       93.12\n",
      "4 2013-01-07       93.20 \n",
      "\n",
      "Holidays DataFrame:\n",
      "        date     type    locale locale_name                    description  \\\n",
      "0 2012-03-02  Holiday     Local       Manta             Fundacion de Manta   \n",
      "1 2012-04-01  Holiday  Regional    Cotopaxi  Provincializacion de Cotopaxi   \n",
      "2 2012-04-12  Holiday     Local      Cuenca            Fundacion de Cuenca   \n",
      "3 2012-04-14  Holiday     Local    Libertad      Cantonizacion de Libertad   \n",
      "4 2012-04-21  Holiday     Local    Riobamba      Cantonizacion de Riobamba   \n",
      "\n",
      "   transferred  \n",
      "0        False  \n",
      "1        False  \n",
      "2        False  \n",
      "3        False  \n",
      "4        False   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#load and check data\n",
    "data_path = \"/Users/carlriemann/Documents/data/\"\n",
    "train_file = data_path + \"train.csv\"\n",
    "test_file = data_path + \"test.csv\"\n",
    "stores_file = data_path + \"stores.csv\"\n",
    "oil_file = data_path + \"oil.csv\"\n",
    "holidays_file = data_path + \"holidays_events.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_file, parse_dates=['date'])\n",
    "test_df = pd.read_csv(test_file, parse_dates=['date'])\n",
    "stores_df = pd.read_csv(stores_file)\n",
    "oil_df = pd.read_csv(oil_file, parse_dates=['date'])\n",
    "holidays_df = pd.read_csv(holidays_file, parse_dates=['date'])\n",
    "\n",
    "\n",
    "print(\"Train DataFrame:\")\n",
    "print(train_df.head(), '\\n')\n",
    "\n",
    "\n",
    "print(\"Test DataFrame:\")\n",
    "print(test_df.head(), '\\n')\n",
    "\n",
    "      \n",
    "print(\"Stores DataFrame:\")\n",
    "print(stores_df.head(), '\\n')\n",
    "\n",
    "print(\"Oil DataFrame:\")\n",
    "print(oil_df.head(), '\\n')\n",
    "\n",
    "print(\"Holidays DataFrame:\")\n",
    "print(holidays_df.head(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8ff1470",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Train DataFrame:\n",
      " id             0\n",
      "date           0\n",
      "store_nbr      0\n",
      "family         0\n",
      "sales          0\n",
      "onpromotion    0\n",
      "dtype: int64 \n",
      "\n",
      "Missing values in Test DataFrame:\n",
      " id             0\n",
      "date           0\n",
      "store_nbr      0\n",
      "family         0\n",
      "onpromotion    0\n",
      "dtype: int64 \n",
      "\n",
      "Missing values in Stores DataFrame:\n",
      " store_nbr    0\n",
      "city         0\n",
      "state        0\n",
      "type         0\n",
      "cluster      0\n",
      "dtype: int64 \n",
      "\n",
      "Missing values in Oil DataFrame:\n",
      " date           0\n",
      "dcoilwtico    43\n",
      "dtype: int64 \n",
      "\n",
      "Missing values in Holidays DataFrame:\n",
      " date           0\n",
      "type           0\n",
      "locale         0\n",
      "locale_name    0\n",
      "description    0\n",
      "transferred    0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#check for missing values\n",
    "print(\"Missing values in Train DataFrame:\\n\", train_df.isnull().sum(), '\\n')\n",
    "print(\"Missing values in Test DataFrame:\\n\", test_df.isnull().sum(), '\\n')\n",
    "print(\"Missing values in Stores DataFrame:\\n\", stores_df.isnull().sum(), '\\n')\n",
    "print(\"Missing values in Oil DataFrame:\\n\", oil_df.isnull().sum(), '\\n')\n",
    "print(\"Missing values in Holidays DataFrame:\\n\", holidays_df.isnull().sum(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4ecf4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill \"dcoilwtico\" by linear interpolation, and forwardfill/backwardfill\n",
    "oil_df['dcoilwtico'] = oil_df['dcoilwtico'].interpolate(method='linear')\n",
    "oil_df['dcoilwtico'] = oil_df['dcoilwtico'].ffill().bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9c7e35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix holidays_df\n",
    "transfer_holidays = holidays_df[holidays_df['type'] == 'Transfer']\n",
    "\n",
    "#For each transfer holiday, find the corresponding original holiday where 'transferred' is True\n",
    "for index, row in transfer_holidays.iterrows():\n",
    "    #Find the original holiday row where transferred is True and the names match (looking for the word Traslado)\n",
    "    original_holiday = holidays_df[(holidays_df['description'] == row['description'].replace(\"Traslado \", \"\")) & (holidays_df['transferred'] == True)]\n",
    "    \n",
    "    if not original_holiday.empty:\n",
    "        #update the row where 'holiday_type' is 'Transfer' with info from the original holiday\n",
    "        holidays_df.at[index, 'description'] = original_holiday['description'].values[0]\n",
    "        holidays_df.at[index, 'date'] = row['date']  #keep the 'Transfer' holiday date\n",
    "        holidays_df.at[index, 'type'] = 'TransferredHoliday'\n",
    "\n",
    "# Step 3: Drop the 'transferred' column\n",
    "holidays_df.drop(columns=['transferred'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fa00fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in Oil DataFrame:\n",
      " date          0\n",
      "dcoilwtico    0\n",
      "dtype: int64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Missing values in Oil DataFrame:\\n\", oil_df.isnull().sum(), '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b33dd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating new date features columns\n",
    "train_df['year'] = train_df['date'].dt.year\n",
    "train_df['month'] = train_df['date'].dt.month\n",
    "train_df['day'] = train_df['date'].dt.day\n",
    "train_df['day_of_week'] = train_df['date'].dt.dayofweek\n",
    "train_df['week_of_year'] = train_df['date'].dt.isocalendar().week\n",
    "\n",
    "test_df['year'] = test_df['date'].dt.year\n",
    "test_df['month'] = test_df['date'].dt.month\n",
    "test_df['day'] = test_df['date'].dt.day\n",
    "test_df['day_of_week'] = test_df['date'].dt.dayofweek\n",
    "test_df['week_of_year'] = test_df['date'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bdf8f9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sales  lag_1  lag_7  rolling_mean_7  rolling_mean_30\n",
      "0    0.0    NaN    NaN             NaN              NaN\n",
      "1    0.0    NaN    NaN             NaN              NaN\n",
      "2    0.0    NaN    NaN             NaN              NaN\n",
      "3    0.0    NaN    NaN             NaN              NaN\n",
      "4    0.0    NaN    NaN             NaN              NaN\n",
      "5    0.0    NaN    NaN             NaN              NaN\n",
      "6    0.0    NaN    NaN             NaN              NaN\n",
      "7    0.0    NaN    NaN             NaN              NaN\n",
      "8    0.0    NaN    NaN             NaN              NaN\n",
      "9    0.0    NaN    NaN             NaN              NaN\n"
     ]
    }
   ],
   "source": [
    "#Creating lag features for sales to capture recent trends.\n",
    "train_df['lag_1'] = train_df.groupby(['store_nbr', 'family'])['sales'].shift(1)\n",
    "train_df['lag_7'] = train_df.groupby(['store_nbr', 'family'])['sales'].shift(7)\n",
    "\n",
    "#Create rolling averages, help the model detect smoother trends\n",
    "train_df['rolling_mean_7'] = train_df.groupby(['store_nbr', 'family'], group_keys=False)['sales'] \\\n",
    "    .rolling(window=7).mean().reset_index(level=['store_nbr', 'family'], drop=True)\n",
    "\n",
    "train_df['rolling_mean_30'] = train_df.groupby(['store_nbr', 'family'], group_keys=False)['sales'] \\\n",
    "    .rolling(window=30).mean().reset_index(level=['store_nbr', 'family'], drop=True)\n",
    "\n",
    "#check the results\n",
    "print(train_df[['sales', 'lag_1', 'lag_7', 'rolling_mean_7', 'rolling_mean_30']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c6536d",
   "metadata": {},
   "source": [
    "#REMEMBER NAN VALUES ARE ADDED TO DATES WITH NO past INFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37fe76c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['lag_1'] = train_df['lag_1'].ffill()\n",
    "train_df['lag_7'] = train_df['lag_7'].ffill()\n",
    "train_df['rolling_mean_7'] = train_df['rolling_mean_7'].ffill()\n",
    "train_df['rolling_mean_30'] = train_df['rolling_mean_30'].ffill()\n",
    "train_df['lag_1'] = train_df['lag_1'].ffill()\n",
    "train_df['lag_7'] = train_df['lag_7'].ffill()\n",
    "train_df['rolling_mean_7'] = train_df['rolling_mean_7'].ffill()\n",
    "train_df['rolling_mean_30'] = train_df['rolling_mean_30'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93b19b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lag features for the test set\n",
    "test_df['lag_1'] = test_df.groupby(['store_nbr', 'family'])['onpromotion'].shift(1)\n",
    "test_df['lag_7'] = test_df.groupby(['store_nbr', 'family'])['onpromotion'].shift(7)\n",
    "\n",
    "# Creating rolling statistics for the test set\n",
    "test_df['rolling_mean_7'] = test_df.groupby(['store_nbr', 'family'], group_keys=False)['onpromotion'] \\\n",
    "    .rolling(window=7).mean().reset_index(level=['store_nbr', 'family'], drop=True)\n",
    "test_df['rolling_mean_30'] = test_df.groupby(['store_nbr', 'family'], group_keys=False)['onpromotion'] \\\n",
    "    .rolling(window=30).mean().reset_index(level=['store_nbr', 'family'], drop=True)\n",
    "\n",
    "# Forward fill any NaN values in the lag and rolling features for the test set\n",
    "test_df['lag_1'] = test_df['lag_1'].ffill()\n",
    "test_df['lag_7'] = test_df['lag_7'].ffill()\n",
    "test_df['rolling_mean_7'] = test_df['rolling_mean_7'].ffill()\n",
    "test_df['rolling_mean_30'] = test_df['rolling_mean_30'].ffill()\n",
    "test_df['lag_1'] = test_df['lag_1'].bfill()\n",
    "test_df['lag_7'] = test_df['lag_7'].bfill()\n",
    "test_df['rolling_mean_7'] = test_df['rolling_mean_7'].bfill()\n",
    "test_df['rolling_mean_30'] = test_df['rolling_mean_30'].bfill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0eb78265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in train_df: Index(['id', 'date', 'store_nbr', 'family', 'sales', 'onpromotion', 'year',\n",
      "       'month', 'day', 'day_of_week', 'week_of_year', 'lag_1', 'lag_7',\n",
      "       'rolling_mean_7', 'rolling_mean_30'],\n",
      "      dtype='object')\n",
      "Columns in test_df: Index(['id', 'date', 'store_nbr', 'family', 'onpromotion', 'year', 'month',\n",
      "       'day', 'day_of_week', 'week_of_year', 'lag_1', 'lag_7',\n",
      "       'rolling_mean_7', 'rolling_mean_30'],\n",
      "      dtype='object')\n",
      "Columns in holidays_df: Index(['date', 'type', 'locale', 'locale_name', 'description'], dtype='object')\n",
      "Columns in oil_df: Index(['date', 'dcoilwtico'], dtype='object')\n",
      "Columns in stores_df: Index(['store_nbr', 'city', 'state', 'type', 'cluster'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Columns in train_df:\", train_df.columns)\n",
    "print(\"Columns in test_df:\", test_df.columns)\n",
    "print(\"Columns in holidays_df:\", holidays_df.columns)\n",
    "print(\"Columns in oil_df:\", oil_df.columns)\n",
    "print(\"Columns in stores_df:\", stores_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a22182",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(stores_df, on='store_nbr', how='left')\n",
    "test_df = test_df.merge(stores_df, on='store_nbr', how='left')\n",
    "print(\"Columns in train_df:\", train_df.columns)\n",
    "print(\"Columns in test_df:\", test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf77e5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.merge(oil_df, on='date', how='left')\n",
    "test_df = test_df.merge(oil_df, on='date', how='left')\n",
    "print(\"Columns in train_df:\", train_df.columns)\n",
    "print(\"Columns in test_df:\", test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7250232e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#transferred TRUE/FALSE means if the holiday was transferred that year or not\n",
    "train_df = train_df.merge(holidays_df[['date', 'type']], on='date', how='left')\n",
    "test_df = test_df.merge(holidays_df[['date', 'type']], on='date', how='left')\n",
    "print(\"Columns in train_df:\", train_df.columns)\n",
    "print(\"Columns in test_df:\", test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6054ae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df)\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a5a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename type_x, type_y\n",
    "train_df.rename(columns={'type_x': 'store_type', 'type_y': 'holiday_type'}, inplace=True)\n",
    "test_df.rename(columns={'type_x': 'store_type', 'type_y': 'holiday_type'}, inplace=True)\n",
    "\n",
    "# Check the column names after renaming\n",
    "print(train_df)\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27bdbf0",
   "metadata": {},
   "source": [
    "There is only 1 holiday date on the test set from the holidays_df dates, explaining why there are so many NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96280659",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df['holiday_type'].fillna('No Holiday', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dea35ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#encode onpromotion, to represent if there was or wasn't a promotion\n",
    "train_df['has_promotion'] = np.where(train_df['onpromotion'] > 0, 1, 0)\n",
    "test_df['has_promotion'] = np.where(test_df['onpromotion'] > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce78ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Columns in train_df:\", train_df.columns)\n",
    "print(\"Columns in test_df:\", test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b6243b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "train_df['year_month'] = train_df['date'].dt.to_period('M')\n",
    "\n",
    "#create a boxplot of sales by year_month\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(x='year_month', y='sales', data=train_df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Boxplot of Sales by Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b467dce4",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37934682",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
